{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comments Classifier : Multi-label Classification (TFX Model Serving).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7FcgN3JdZr",
        "colab_type": "code",
        "outputId": "121a1515-9546-40a6-c591-30c8e97d7bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import  classification_report\n",
        "!gdown --id 1pdgCAl-Rbm0ou_wLqt4D2f_TaymWOUII"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pdgCAl-Rbm0ou_wLqt4D2f_TaymWOUII\n",
            "To: /content/train.csv\n",
            "68.8MB [00:00, 79.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urm6cGRUUR9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data\n",
        "data = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVIgnz24FtC6",
        "colab_type": "code",
        "outputId": "3fef6053-bafa-4d20-ad4c-d85a901937cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XbH7tEbFvPG",
        "colab_type": "code",
        "outputId": "d2ea2cbb-448f-4fd9-e24f-49ac2e84a469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Distribution as per all the labels\n",
        "classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "for label in classes:\n",
        "  print('Distribution:\\n{}\\n'.format((data[label].value_counts()/data.shape[0])*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution:\n",
            "0    90.415552\n",
            "1     9.584448\n",
            "Name: toxic, dtype: float64\n",
            "\n",
            "Distribution:\n",
            "0    99.000445\n",
            "1     0.999555\n",
            "Name: severe_toxic, dtype: float64\n",
            "\n",
            "Distribution:\n",
            "0    94.705178\n",
            "1     5.294822\n",
            "Name: obscene, dtype: float64\n",
            "\n",
            "Distribution:\n",
            "0    99.700447\n",
            "1     0.299553\n",
            "Name: threat, dtype: float64\n",
            "\n",
            "Distribution:\n",
            "0    95.063639\n",
            "1     4.936361\n",
            "Name: insult, dtype: float64\n",
            "\n",
            "Distribution:\n",
            "0    99.119514\n",
            "1     0.880486\n",
            "Name: identity_hate, dtype: float64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga8OqBblE2To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Test Split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(data.comment_text, data[classes].values, test_size=0.2, random_state=42)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW7vsW3yEtt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_input_fn(texts, labels, batch_size=32, is_training=True):\n",
        "  # Convert the inputs to a Dataset.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((texts,labels))\n",
        "  # Shuffle, repeat, and batch the examples.\n",
        "  dataset = dataset.cache()\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "  # Return the dataset.\n",
        "  return dataset\n",
        "\n",
        "# Creating Vectorization Layer\n",
        "max_features = 5000\n",
        "max_len = 50\n",
        "vectorization_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=max_features, output_sequence_length=max_len)\n",
        "vectorization_layer.adapt(train_texts.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_cO1srj3HIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting embeddings\n",
        "def create_model():\n",
        "  words = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "  vectors = vectorization_layer(words)\n",
        "  embeddings = tf.keras.layers.Embedding(input_dim=max_features+1, output_dim=128)(vectors)\n",
        "  output = tf.keras.layers.LSTM(256, return_state=True, return_sequences=True, name='LSTM_1')(embeddings)\n",
        "  output = tf.keras.layers.LSTM(256, name='LSTM_2')(output)\n",
        "  output = tf.keras.layers.Dense(64, activation='relu', name='Dense_3')(output)\n",
        "  output = tf.keras.layers.Dense(6,activation='sigmoid', name='Output')(output)\n",
        "\n",
        "  model = tf.keras.models.Model(words,output)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtU9yBKTL8w7",
        "colab_type": "code",
        "outputId": "3d8677e3-3d49-4fd2-c475-5706c642d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# For TPU execution\n",
        "'''\n",
        "import os\n",
        "try:\n",
        " device_name = os.environ['COLAB_TPU_ADDR']\n",
        " TPU_ADDRESS = 'grpc://' + device_name\n",
        " print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        " print('TPU not found')\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Data\n",
        "training_dataset = data_input_fn(train_texts, train_labels)\n",
        "validation_dataset = data_input_fn(val_texts, val_labels, batch_size=512, is_training=False)\n",
        "test_dataset = data_input_fn(test_texts, test_labels, batch_size=512, is_training=False)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "steps_per_epoch = train_sequences.shape[0] // batch_size\n",
        "\n",
        "model.fit(training_dataset, epochs=epochs, batch_size=batch_size, \n",
        "          steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\n",
        "'''          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\ntry:\\n device_name = os.environ[\\'COLAB_TPU_ADDR\\']\\n TPU_ADDRESS = \\'grpc://\\' + device_name\\n print(\\'Found TPU at: {}\\'.format(TPU_ADDRESS))\\nexcept KeyError:\\n print(\\'TPU not found\\')\\n\\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\\'grpc://\\' + os.environ[\\'COLAB_TPU_ADDR\\'])\\ntf.config.experimental_connect_to_cluster(resolver)\\n# This is the TPU initialization code that has to be at the beginning.\\ntf.tpu.experimental.initialize_tpu_system(resolver)\\nprint(\"All devices: \", tf.config.list_logical_devices(\\'TPU\\'))\\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\\n\\nwith strategy.scope():\\n  model = create_model()\\n  model.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\n# Data\\ntraining_dataset = data_input_fn(train_texts, train_labels)\\nvalidation_dataset = data_input_fn(val_texts, val_labels, batch_size=512, is_training=False)\\ntest_dataset = data_input_fn(test_texts, test_labels, batch_size=512, is_training=False)\\n\\nbatch_size = 32\\nepochs = 100\\nsteps_per_epoch = train_sequences.shape[0] // batch_size\\n\\nmodel.fit(training_dataset, epochs=epochs, batch_size=batch_size, \\n          steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0b7UMsz5e1D",
        "colab_type": "code",
        "outputId": "b4c631ae-1727-449b-9b42-c7cc6b8929d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# For GPU Execution\n",
        "model = create_model()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Data\n",
        "training_dataset = data_input_fn(train_texts, train_labels)\n",
        "validation_dataset = data_input_fn(val_texts, val_labels, batch_size=512, is_training=False)\n",
        "test_dataset = data_input_fn(test_texts, test_labels, batch_size=512, is_training=False)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "steps_per_epoch = train_texts.shape[0] // batch_size\n",
        "\n",
        "model.fit(training_dataset, epochs=epochs, batch_size=batch_size, \n",
        "          steps_per_epoch=steps_per_epoch, validation_data=validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3191/3191 [==============================] - 190s 60ms/step - loss: 0.1278 - accuracy: 0.9645 - val_loss: 0.0971 - val_accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32bed6e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbeQ3GQKawu",
        "colab_type": "code",
        "outputId": "2c91b152-86ed-40a2-cfbe-8865ec23d089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.predict(['I hate black people'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19375521, 0.01254728, 0.10115671, 0.00688036, 0.08974175,\n",
              "        0.02121467]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7v7ypM8XKig",
        "colab_type": "code",
        "outputId": "3f46dd22-4063-42ad-9c55-efdb013dd648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 3s 53ms/step - loss: 0.0965 - accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09646929800510406, 0.994140625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYjpzxwCYBL9",
        "colab_type": "code",
        "outputId": "8e108214-6824-4749-86d3-67fdcba2fd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Test\n",
        "model.predict(['You are an asshole!'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6161914 , 0.13870525, 0.42414263, 0.03978828, 0.40349987,\n",
              "        0.08646153]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j961k9NnYTpV",
        "colab_type": "code",
        "outputId": "01c72fdc-b5c9-4b31-cd59-219e7bf8ded1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Model Evaluation and Inference functions\n",
        "def evaluate(predictions, truth):\n",
        "  thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "  for val in thresholds:\n",
        "    pred = predictions.copy()\n",
        "    pred = np.where(pred>=val,1,0)\n",
        "    report = classification_report(truth, pred)\n",
        "    print(\"Classification report for threshold {}\".format(val))\n",
        "    print(\"Classification Report:\\n {}\\n\".format(report))\n",
        "\n",
        "evaluate(model.predict(test_texts), test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for threshold 0.1\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.67      0.53      3056\n",
            "           1       0.24      0.64      0.35       321\n",
            "           2       0.46      0.61      0.53      1715\n",
            "           3       0.13      0.03      0.04        74\n",
            "           4       0.46      0.59      0.52      1614\n",
            "           5       0.11      0.18      0.14       294\n",
            "\n",
            "   micro avg       0.41      0.61      0.49      7074\n",
            "   macro avg       0.31      0.45      0.35      7074\n",
            "weighted avg       0.42      0.61      0.49      7074\n",
            " samples avg       0.05      0.06      0.05      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.2\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.50      0.56      3056\n",
            "           1       0.27      0.16      0.20       321\n",
            "           2       0.60      0.48      0.53      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.58      0.46      0.51      1614\n",
            "           5       0.27      0.01      0.02       294\n",
            "\n",
            "   micro avg       0.60      0.44      0.51      7074\n",
            "   macro avg       0.39      0.27      0.30      7074\n",
            "weighted avg       0.57      0.44      0.50      7074\n",
            " samples avg       0.04      0.04      0.04      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.3\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.40      0.52      3056\n",
            "           1       0.67      0.01      0.01       321\n",
            "           2       0.67      0.40      0.50      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.64      0.39      0.49      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.69      0.36      0.47      7074\n",
            "   macro avg       0.45      0.20      0.25      7074\n",
            "weighted avg       0.65      0.36      0.46      7074\n",
            " samples avg       0.03      0.03      0.03      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.4\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.32      0.46      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       0.76      0.31      0.44      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.73      0.29      0.41      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.77      0.28      0.41      7074\n",
            "   macro avg       0.38      0.15      0.22      7074\n",
            "weighted avg       0.69      0.28      0.40      7074\n",
            " samples avg       0.03      0.02      0.02      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.5\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.27      0.41      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       0.85      0.11      0.20      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.74      0.04      0.08      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.83      0.15      0.26      7074\n",
            "   macro avg       0.40      0.07      0.11      7074\n",
            "weighted avg       0.73      0.15      0.24      7074\n",
            " samples avg       0.03      0.01      0.02      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.6\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.19      0.32      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       1.00      0.00      0.00      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       1.00      0.00      0.00      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.90      0.08      0.15      7074\n",
            "   macro avg       0.48      0.03      0.05      7074\n",
            "weighted avg       0.86      0.08      0.14      7074\n",
            " samples avg       0.02      0.01      0.01      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.7\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.00      0.01      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       0.00      0.00      0.00      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.00      0.00      0.00      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.94      0.00      0.00      7074\n",
            "   macro avg       0.16      0.00      0.00      7074\n",
            "weighted avg       0.41      0.00      0.00      7074\n",
            " samples avg       0.00      0.00      0.00      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.8\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       0.00      0.00      0.00      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.00      0.00      0.00      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       1.00      0.00      0.00      7074\n",
            "   macro avg       0.17      0.00      0.00      7074\n",
            "weighted avg       0.43      0.00      0.00      7074\n",
            " samples avg       0.00      0.00      0.00      7074\n",
            "\n",
            "\n",
            "Classification report for threshold 0.9\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      3056\n",
            "           1       0.00      0.00      0.00       321\n",
            "           2       0.00      0.00      0.00      1715\n",
            "           3       0.00      0.00      0.00        74\n",
            "           4       0.00      0.00      0.00      1614\n",
            "           5       0.00      0.00      0.00       294\n",
            "\n",
            "   micro avg       0.00      0.00      0.00      7074\n",
            "   macro avg       0.00      0.00      0.00      7074\n",
            "weighted avg       0.00      0.00      0.00      7074\n",
            " samples avg       0.00      0.00      0.00      7074\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuQFbuNFnAgu",
        "colab_type": "code",
        "outputId": "2789bf5c-0dab-48a3-9eb5-9b4436e9fe8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEfSrnXman5K",
        "colab_type": "code",
        "outputId": "927311de-dbb6-41bf-93a8-b502f218c01e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Saving Model\n",
        "MODEL_DIR = os.getcwd()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "export_path = /content/1\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/1/assets\n",
            "\n",
            "Saved model:\n",
            "total 1752\n",
            "drwxr-xr-x 2 root root    4096 Jun  9 15:13 assets\n",
            "-rw-r--r-- 1 root root 1782893 Jun  9 15:13 saved_model.pb\n",
            "drwxr-xr-x 2 root root    4096 Jun  9 15:13 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGOsaJEbZeP8",
        "colab_type": "code",
        "outputId": "94e54616-2ddc-422b-de6d-9db84f9546b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_2'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_input_2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['Output'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 6)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0609 15:13:36.065053 140702980573056 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-06-09 15:13:36.246117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-09 15:13:36.249667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.250487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-06-09 15:13:36.250793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-09 15:13:36.254976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-09 15:13:36.256875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-09 15:13:36.257233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-09 15:13:36.267344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-09 15:13:36.283105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-09 15:13:36.294031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-09 15:13:36.294193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.295025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.295708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-06-09 15:13:36.348281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2020-06-09 15:13:36.348631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fda1dd800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-09 15:13:36.348670: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-09 15:13:36.409995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.410924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fdbee9a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-09 15:13:36.410966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-06-09 15:13:36.411175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.412010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-06-09 15:13:36.412096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-09 15:13:36.412139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-09 15:13:36.412189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-09 15:13:36.412262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-09 15:13:36.412332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-09 15:13:36.412373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-09 15:13:36.412413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-09 15:13:36.412631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.413481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.414262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-06-09 15:13:36.417841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-09 15:13:36.419277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-09 15:13:36.419315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2020-06-09 15:13:36.419334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2020-06-09 15:13:36.419671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.420433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-09 15:13:36.421232: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-09 15:13:36.421306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10104 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0609 15:13:36.559463 140702980573056 util.py:148] Unused attribute in object (root).layer_with_weights-0._index_lookup_layer._table: [u'table', u'table']\n",
            "W0609 15:13:36.559706 140702980573056 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'input_2')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          input_2: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'input_2')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.string, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj1fB4-lbg11",
        "colab_type": "code",
        "outputId": "5b1f80d8-c4b4-438b-b4ea-637570adb4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Updating apt repo for tensorflow-model-server\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  40875      0 --:--:-- --:--:-- --:--:-- 40875\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [162 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [933 kB]\n",
            "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,830 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,230 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [856 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,387 kB]\n",
            "Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [883 kB]\n",
            "Fetched 7,616 kB in 3s (2,186 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "66 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z55ap9z-b59Y",
        "colab_type": "code",
        "outputId": "b02e14f8-5218-46c1-eddb-32042b53a2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Installing Tensorflow Model Server\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 187 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.2.0 [187 MB]\n",
            "Fetched 187 MB in 3s (67.3 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.2.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.2.0) ...\n",
            "Setting up tensorflow-model-server (2.2.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKO4ZqAMcBhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding models directory to env variables\n",
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSZgWRv8cZ90",
        "colab_type": "code",
        "outputId": "f3ddef42-f3c6-44d7-a005-450af35c10aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=sample_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47BHsO22c3Jh",
        "colab_type": "code",
        "outputId": "1edcd1c4-737b-4139-b323-5906995cb078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-09 15:13:57.653803: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-06-09 15:13:57.755291: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
            "2020-06-09 15:13:57.931910: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /content/1\n",
            "2020-06-09 15:13:58.053686: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:364] SavedModel load for tags { serve }; Status: success: OK. Took 431720 microseconds.\n",
            "2020-06-09 15:13:58.069180: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /content/1/assets.extra/tf_serving_warmup_requests\n",
            "2020-06-09 15:13:58.069357: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: sample_model version: 1}\n",
            "2020-06-09 15:13:58.071346: I tensorflow_serving/model_servers/server.cc:355] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2020-06-09 15:13:58.072087: I tensorflow_serving/model_servers/server.cc:375] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW_LR-MRc7Mr",
        "colab_type": "code",
        "outputId": "850293a3-2d60-48fa-c0f5-d410388a3772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "test_case = [['Fuck off! I do not love you']]\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_case})\n",
        "print('Data: {}'.format(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": [[\"Fuck off! I do not love you\"]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-EZfkVdHlx",
        "colab_type": "code",
        "outputId": "cccf86dd-9602-4836-fcf9-403b153d8aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/sample_model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'predictions': [[0.600387394, 0.0921687856, 0.383404642, 0.0241133831, 0.360389948, 0.0641452521]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5t-wHRppdy1",
        "colab_type": "code",
        "outputId": "d73438b0-24a9-4e04-b1f5-03f757912bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.predict(['Fuck off! I do not love you'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6003875 , 0.09216882, 0.38340476, 0.02411339, 0.36039   ,\n",
              "        0.06414524]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYTZgyYp6TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}